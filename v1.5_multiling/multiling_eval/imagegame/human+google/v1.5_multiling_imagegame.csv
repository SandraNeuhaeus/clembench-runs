lang,model,clemscore (Played * Success),% Played,% Success (of Played),Aborted at Player 1 (of Aborted)
de,Meta-Llama-3.1-70B-Instruct,43.38,50.0,86.75,95.0
de,Qwen1.5-72B-Chat,8.4,22.5,37.33,61.29
de,Llama-3-70B-Instruct,,0.0,,100.0
de,Llama-3-SauerkrautLM-70b-Instruct,,0.0,,100.0
de,Mixtral-8x22B-Instruct-v0.1,,0.0,,100.0
de,aya-23-35B,,0.0,,100.0
de_google,Llama-3-70B-Instruct,,0.0,,100.0
de_google,Mixtral-8x22B-Instruct-v0.1,,0.0,,100.0
en,Meta-Llama-3.1-70B-Instruct,85.82,92.5,92.78,66.67
en,Qwen1.5-72B-Chat,34.25,75.0,45.67,30.0
en,Llama-3-SauerkrautLM-70b-Instruct,10.07,12.5,80.6,94.29
en,Llama-3-70B-Instruct,2.5,2.5,100.0,100.0
en,Mixtral-8x22B-Instruct-v0.1,,0.0,,100.0
en,aya-23-35B,,0.0,,100.0
es,Meta-Llama-3.1-70B-Instruct,59.08,67.5,87.52,92.31
es,Llama-3-70B-Instruct,5.0,5.0,100.0,100.0
es,Llama-3-SauerkrautLM-70b-Instruct,3.75,5.0,75.0,100.0
es,Qwen1.5-72B-Chat,2.43,2.5,97.0,82.05
es,Mixtral-8x22B-Instruct-v0.1,,0.0,,100.0
es,aya-23-35B,,0.0,,100.0
es_google,Llama-3-70B-Instruct,,0.0,,100.0
es_google,Mixtral-8x22B-Instruct-v0.1,,0.0,,100.0
ru,Meta-Llama-3.1-70B-Instruct,52.4,65.0,80.62,100.0
ru,Qwen1.5-72B-Chat,11.43,45.0,25.39,45.45
ru,Llama-3-SauerkrautLM-70b-Instruct,1.52,2.5,61.0,100.0
ru,Llama-3-70B-Instruct,,0.0,,100.0
ru,Mixtral-8x22B-Instruct-v0.1,,0.0,,95.0
ru,aya-23-35B,,0.0,,100.0
ru_google,Llama-3-70B-Instruct,2.5,2.5,100.0,100.0
ru_google,Mixtral-8x22B-Instruct-v0.1,,0.0,,100.0
te,Llama-3-SauerkrautLM-70b-Instruct,1.45,5.0,29.0,86.84
te,Qwen1.5-72B-Chat,0.43,17.5,2.43,57.58
te,Llama-3-70B-Instruct,,0.0,,100.0
te,Meta-Llama-3.1-70B-Instruct,,0.0,,100.0
te,Mixtral-8x22B-Instruct-v0.1,,0.0,,82.5
te,aya-23-35B,,0.0,,47.5
te_google,Llama-3-70B-Instruct,,0.0,,100.0
te_google,Mixtral-8x22B-Instruct-v0.1,,0.0,,77.5
tk,Meta-Llama-3.1-70B-Instruct,5.45,10.0,54.5,100.0
tk,Llama-3-70B-Instruct,,0.0,,100.0
tk,Llama-3-SauerkrautLM-70b-Instruct,,0.0,,100.0
tk,Mixtral-8x22B-Instruct-v0.1,,0.0,,100.0
tk,Qwen1.5-72B-Chat,,0.0,,0.0
tk,aya-23-35B,,0.0,,0.0
tk_google,Llama-3-70B-Instruct,,0.0,,100.0
tk_google,Mixtral-8x22B-Instruct-v0.1,,0.0,,100.0
tr,Meta-Llama-3.1-70B-Instruct,32.4,37.5,86.4,88.0
tr,Llama-3-70B-Instruct,,0.0,,100.0
tr,Llama-3-SauerkrautLM-70b-Instruct,,0.0,,100.0
tr,Mixtral-8x22B-Instruct-v0.1,,0.0,,100.0
tr,Qwen1.5-72B-Chat,,0.0,,100.0
tr,aya-23-35B,,0.0,,100.0
tr_google,Llama-3-70B-Instruct,,0.0,,100.0
tr_google,Mixtral-8x22B-Instruct-v0.1,,0.0,,100.0
